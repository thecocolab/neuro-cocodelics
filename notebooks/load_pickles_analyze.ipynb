{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "🔍 Analyzing: ../results/lsd_closed_hamza/lsd_closed_hamza_binary_baseline_rs42.pkl\n",
            "============================================================\n",
            "✅ Successfully loaded pickle file\n",
            "📊 Root object type: <class 'dict'>\n",
            "📏 Root object length: 3\n",
            "📁 Dictionary with 3 keys:\n",
            "   🔑 Logistic Regression: <class 'dict'> (length: 6)\n",
            "   🔑 Random Forest: <class 'dict'> (length: 6)\n",
            "   🔑 SVC: <class 'dict'> (length: 6)\n",
            "\n",
            "================================================================================\n",
            "🔍 Analyzing: ../results/lsd_closed_hamza/lsd_closed_Hamza.pkl\n",
            "============================================================\n",
            "✅ Successfully loaded pickle file\n",
            "📊 Root object type: <class 'dict'>\n",
            "📏 Root object length: 1\n",
            "📁 Dictionary with 1 keys:\n",
            "   🔑 classification_baseline: <class 'dict'> (length: 271)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "import os\n",
        "\n",
        "def load_and_analyze_pickle(file_path):\n",
        "    \"\"\"Load and analyze a pickle file structure\"\"\"\n",
        "    print(f\"🔍 Analyzing: {file_path}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"❌ File not found: {file_path}\")\n",
        "        return None\n",
        "    \n",
        "    # Load the pickle file\n",
        "    try:\n",
        "        with open(file_path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "        print(f\"✅ Successfully loaded pickle file\")\n",
        "        print(f\"📊 Root object type: {type(data)}\")\n",
        "        \n",
        "        if hasattr(data, '__len__'):\n",
        "            print(f\"📏 Root object length: {len(data)}\")\n",
        "        \n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading pickle: {e}\")\n",
        "        return None\n",
        "\n",
        "def explore_dict_structure(data, max_items=10, max_depth=2, current_depth=0):\n",
        "    \"\"\"Explore dictionary structure recursively\"\"\"\n",
        "    indent = \"  \" * current_depth\n",
        "    \n",
        "    if isinstance(data, dict):\n",
        "        print(f\"{indent}📁 Dictionary with {len(data)} keys:\")\n",
        "        \n",
        "        for i, (key, value) in enumerate(data.items()):\n",
        "            if i >= max_items:\n",
        "                print(f\"{indent}   ... and {len(data) - max_items} more keys\")\n",
        "                break\n",
        "                \n",
        "            print(f\"{indent}   🔑 {key}: {type(value)}\", end=\"\")\n",
        "            \n",
        "            if hasattr(value, '__len__') and not isinstance(value, str):\n",
        "                print(f\" (length: {len(value)})\")\n",
        "            else:\n",
        "                print()\n",
        "            \n",
        "            # Show sample values for simple types\n",
        "            if isinstance(value, (str, int, float, bool)) and len(str(value)) < 100:\n",
        "                print(f\"{indent}      💡 Value: {value}\")\n",
        "            \n",
        "            # Recurse for nested structures (limited depth)\n",
        "            if current_depth < max_depth and isinstance(value, dict) and len(value) <= 5:\n",
        "                explore_dict_structure(value, max_items, max_depth, current_depth + 1)\n",
        "    \n",
        "    elif isinstance(data, list):\n",
        "        print(f\"{indent}📋 List with {len(data)} items\")\n",
        "        if len(data) > 0:\n",
        "            print(f\"{indent}   First item type: {type(data[0])}\")\n",
        "            if len(data) <= 5:\n",
        "                for i, item in enumerate(data):\n",
        "                    print(f\"{indent}   [{i}]: {type(item)}\")\n",
        "    else:\n",
        "        print(f\"{indent}📄 Single object: {type(data)}\")\n",
        "\n",
        "# Load both pickle files\n",
        "files_to_analyze = [\n",
        "    '../results/lsd_closed_hamza/lsd_closed_hamza_binary_baseline_rs42.pkl',\n",
        "    '../results/lsd_closed_hamza/lsd_closed_Hamza.pkl'\n",
        "]\n",
        "\n",
        "results = {}\n",
        "for file_path in files_to_analyze:\n",
        "    file_name = os.path.basename(file_path)\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    results[file_name] = load_and_analyze_pickle(file_path)\n",
        "    if results[file_name] is not None:\n",
        "        explore_dict_structure(results[file_name], max_items=5, max_depth=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔬 DETAILED ANALYSIS: Binary Baseline File\n",
            "================================================================================\n",
            "📋 Found 3 models:\n",
            "\n",
            "🤖 Model: Logistic Regression\n",
            "   📊 Data keys: ['model_name', 'metric_scores', 'feature_importances', 'predictions', 'params', 'folds_estimators']\n",
            "   📈 Metrics available: ['accuracy', 'f1', 'roc_auc']\n",
            "      accuracy: ['mean', 'std', 'fold_scores']\n",
            "         mean: 0.5667\n",
            "         std: 0.1167\n",
            "      f1: ['mean', 'std', 'fold_scores']\n",
            "         mean: 0.5508\n",
            "         std: 0.1108\n",
            "      roc_auc: ['mean', 'std', 'fold_scores']\n",
            "         mean: 0.5667\n",
            "         std: 0.1167\n",
            "   🎯 Feature importance keys: ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_11']\n",
            "      Number of features: 12\n",
            "   🎲 Prediction keys: ['y_true', 'y_pred', 'y_proba', 'fold_preds']\n",
            "\n",
            "🤖 Model: Random Forest\n",
            "   📊 Data keys: ['model_name', 'metric_scores', 'feature_importances', 'predictions', 'params', 'folds_estimators']\n",
            "   📈 Metrics available: ['accuracy', 'f1', 'roc_auc']\n",
            "      accuracy: ['mean', 'std', 'fold_scores']\n",
            "         mean: 0.6000\n",
            "         std: 0.0935\n",
            "      f1: ['mean', 'std', 'fold_scores']\n",
            "         mean: 0.5503\n",
            "         std: 0.1386\n",
            "      roc_auc: ['mean', 'std', 'fold_scores']\n",
            "         mean: 0.6000\n",
            "         std: 0.0935\n",
            "   🎯 Feature importance keys: ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_11']\n",
            "      Number of features: 12\n",
            "   🎲 Prediction keys: ['y_true', 'y_pred', 'y_proba', 'fold_preds']\n",
            "\n",
            "🤖 Model: SVC\n",
            "   📊 Data keys: ['model_name', 'metric_scores', 'feature_importances', 'predictions', 'params', 'folds_estimators']\n",
            "   📈 Metrics available: ['accuracy', 'f1', 'roc_auc']\n",
            "      accuracy: ['mean', 'std', 'fold_scores']\n",
            "         mean: 0.6000\n",
            "         std: 0.1458\n",
            "      f1: ['mean', 'std', 'fold_scores']\n",
            "         mean: 0.5445\n",
            "         std: 0.1802\n",
            "      roc_auc: ['mean', 'std', 'fold_scores']\n",
            "         mean: 0.6000\n",
            "         std: 0.1458\n",
            "   🎯 Feature importance keys: []\n",
            "      Number of features: 0\n",
            "   🎲 Prediction keys: ['y_true', 'y_pred', 'y_proba', 'fold_preds']\n"
          ]
        }
      ],
      "source": [
        "# Detailed analysis of the binary baseline file (smaller file)\n",
        "print(\"🔬 DETAILED ANALYSIS: Binary Baseline File\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "binary_file = 'lsd_closed_hamza_binary_baseline_rs42.pkl'\n",
        "if binary_file in results and results[binary_file] is not None:\n",
        "    data = results[binary_file]\n",
        "    \n",
        "    print(f\"📋 Found {len(data)} models:\")\n",
        "    for model_name, model_data in data.items():\n",
        "        print(f\"\\n🤖 Model: {model_name}\")\n",
        "        print(f\"   📊 Data keys: {list(model_data.keys())}\")\n",
        "        \n",
        "        # Analyze metric scores\n",
        "        if 'metric_scores' in model_data:\n",
        "            metrics = model_data['metric_scores']\n",
        "            print(f\"   📈 Metrics available: {list(metrics.keys())}\")\n",
        "            \n",
        "            # Show sample metric scores\n",
        "            for metric_name, metric_data in metrics.items():\n",
        "                if isinstance(metric_data, dict):\n",
        "                    print(f\"      {metric_name}: {list(metric_data.keys())}\")\n",
        "                    # Show actual values if they're simple\n",
        "                    for sub_key, sub_value in metric_data.items():\n",
        "                        if isinstance(sub_value, (int, float, np.number)):\n",
        "                            print(f\"         {sub_key}: {sub_value:.4f}\")\n",
        "        \n",
        "        # Analyze feature importances\n",
        "        if 'feature_importances' in model_data:\n",
        "            fi = model_data['feature_importances']\n",
        "            if isinstance(fi, dict):\n",
        "                print(f\"   🎯 Feature importance keys: {list(fi.keys())}\")\n",
        "                print(f\"      Number of features: {len(fi)}\")\n",
        "        \n",
        "        # Analyze predictions\n",
        "        if 'predictions' in model_data:\n",
        "            pred = model_data['predictions']\n",
        "            if isinstance(pred, dict):\n",
        "                print(f\"   🎲 Prediction keys: {list(pred.keys())}\")\n",
        "else:\n",
        "    print(\"❌ Binary baseline file not loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔬 DETAILED ANALYSIS: Large Hamza File\n",
            "================================================================================\n",
            "📋 Root keys: ['classification_baseline']\n",
            "\n",
            "📊 Classification baseline contains 271 subjects\n",
            "🏷️  First 10 subject IDs: ['MRC41', 'MLF61', 'MLC15', 'MRP32', 'MRT41', 'MLF41', 'MLT55', 'MRF25', 'MRC16', 'MRO14']\n",
            "\n",
            "🔍 Structure of first subject (MRC41):\n",
            "   Type: <class 'dict'>\n",
            "   Length: 3\n",
            "   Keys: ['Logistic Regression', 'Random Forest', 'SVC']\n",
            "      Logistic Regression: <class 'dict'> (length: 6)\n",
            "      Random Forest: <class 'dict'> (length: 6)\n",
            "      SVC: <class 'dict'> (length: 6)\n",
            "\n",
            "📈 PATTERN ANALYSIS across all 271 subjects:\n",
            "   🔑 Unique keys found across all subjects: ['Logistic Regression', 'Random Forest', 'SVC']\n",
            "   📊 Key frequency across subjects:\n",
            "      Logistic Regression: 271/271 subjects (100.0%)\n",
            "      Random Forest: 271/271 subjects (100.0%)\n",
            "      SVC: 271/271 subjects (100.0%)\n"
          ]
        }
      ],
      "source": [
        "# Detailed analysis of the large Hamza file\n",
        "print(\"🔬 DETAILED ANALYSIS: Large Hamza File\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "hamza_file = 'lsd_closed_Hamza.pkl'\n",
        "if hamza_file in results and results[hamza_file] is not None:\n",
        "    data = results[hamza_file]\n",
        "    \n",
        "    print(f\"📋 Root keys: {list(data.keys())}\")\n",
        "    \n",
        "    # Analyze the classification_baseline structure\n",
        "    if 'classification_baseline' in data:\n",
        "        baseline_data = data['classification_baseline']\n",
        "        print(f\"\\n📊 Classification baseline contains {len(baseline_data)} subjects\")\n",
        "        \n",
        "        # Show first few subject IDs\n",
        "        subject_ids = list(baseline_data.keys())[:10]\n",
        "        print(f\"🏷️  First 10 subject IDs: {subject_ids}\")\n",
        "        \n",
        "        # Analyze structure of first subject\n",
        "        if len(baseline_data) > 0:\n",
        "            first_subject_id = list(baseline_data.keys())[0]\n",
        "            first_subject_data = baseline_data[first_subject_id]\n",
        "            \n",
        "            print(f\"\\n🔍 Structure of first subject ({first_subject_id}):\")\n",
        "            print(f\"   Type: {type(first_subject_data)}\")\n",
        "            \n",
        "            if hasattr(first_subject_data, '__len__'):\n",
        "                print(f\"   Length: {len(first_subject_data)}\")\n",
        "            \n",
        "            # If it's a dict, show its keys\n",
        "            if isinstance(first_subject_data, dict):\n",
        "                print(f\"   Keys: {list(first_subject_data.keys())}\")\n",
        "                \n",
        "                # Show sample values for each key\n",
        "                for key, value in first_subject_data.items():\n",
        "                    print(f\"      {key}: {type(value)}\", end=\"\")\n",
        "                    if hasattr(value, '__len__') and not isinstance(value, str):\n",
        "                        print(f\" (length: {len(value)})\")\n",
        "                    else:\n",
        "                        print()\n",
        "                    \n",
        "                    # Show actual values for simple types\n",
        "                    if isinstance(value, (str, int, float, bool)) and len(str(value)) < 100:\n",
        "                        print(f\"         Value: {value}\")\n",
        "                    elif isinstance(value, (list, np.ndarray)) and len(value) <= 10:\n",
        "                        print(f\"         Sample values: {value}\")\n",
        "        \n",
        "        # Analyze patterns across subjects\n",
        "        print(f\"\\n📈 PATTERN ANALYSIS across all {len(baseline_data)} subjects:\")\n",
        "        \n",
        "        # Collect all unique keys from all subjects\n",
        "        all_keys = set()\n",
        "        for subject_data in baseline_data.values():\n",
        "            if isinstance(subject_data, dict):\n",
        "                all_keys.update(subject_data.keys())\n",
        "        \n",
        "        if all_keys:\n",
        "            print(f\"   🔑 Unique keys found across all subjects: {sorted(all_keys)}\")\n",
        "            \n",
        "            # Check consistency - do all subjects have the same keys?\n",
        "            key_counts = {}\n",
        "            for subject_data in baseline_data.values():\n",
        "                if isinstance(subject_data, dict):\n",
        "                    for key in subject_data.keys():\n",
        "                        key_counts[key] = key_counts.get(key, 0) + 1\n",
        "            \n",
        "            print(f\"   📊 Key frequency across subjects:\")\n",
        "            for key, count in sorted(key_counts.items()):\n",
        "                percentage = (count / len(baseline_data)) * 100\n",
        "                print(f\"      {key}: {count}/{len(baseline_data)} subjects ({percentage:.1f}%)\")\n",
        "else:\n",
        "    print(\"❌ Large Hamza file not loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 SUMMARY AND COMPARISON\n",
            "================================================================================\n",
            "📁 lsd_closed_hamza_binary_baseline_rs42.pkl: 0.68 MB\n",
            "📁 lsd_closed_Hamza.pkl: 190.34 MB\n",
            "\n",
            "🔍 STRUCTURE COMPARISON:\n",
            "----------------------------------------\n",
            "Binary Baseline File:\n",
            "  • Structure: Dictionary with 3 ML models\n",
            "  • Models: ['Logistic Regression', 'Random Forest', 'SVC']\n",
            "  • Each model contains: ['model_name', 'metric_scores', 'feature_importances', 'predictions', 'params', 'folds_estimators']\n",
            "\n",
            "Large Hamza File:\n",
            "  • Structure: Dictionary with 1 top-level key(s)\n",
            "  • Contains: 271 subject records\n",
            "  • Subject ID pattern: ['MRC41', 'MLF61', 'MLC15']... (showing first 3)\n",
            "\n",
            "💡 KEY INSIGHTS:\n",
            "  • Binary baseline file: Contains ML model results (3 models with metrics)\n",
            "  • Large Hamza file: Contains individual subject data (271 subjects)\n",
            "  • These appear to be different types of ML analysis results\n",
            "  • Binary baseline: Model comparison results\n",
            "  • Large Hamza: Subject-level analysis results\n"
          ]
        }
      ],
      "source": [
        "# Summary and comparison\n",
        "print(\"📊 SUMMARY AND COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# File size comparison\n",
        "import os\n",
        "files = [\n",
        "    '../results/lsd_closed_hamza/lsd_closed_hamza_binary_baseline_rs42.pkl',\n",
        "    '../results/lsd_closed_hamza/lsd_closed_Hamza.pkl'\n",
        "]\n",
        "\n",
        "for file_path in files:\n",
        "    if os.path.exists(file_path):\n",
        "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
        "        print(f\"📁 {os.path.basename(file_path)}: {size_mb:.2f} MB\")\n",
        "\n",
        "print(\"\\n🔍 STRUCTURE COMPARISON:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "binary_file = 'lsd_closed_hamza_binary_baseline_rs42.pkl'\n",
        "hamza_file = 'lsd_closed_Hamza.pkl'\n",
        "\n",
        "if binary_file in results and results[binary_file] is not None:\n",
        "    binary_data = results[binary_file]\n",
        "    print(f\"Binary Baseline File:\")\n",
        "    print(f\"  • Structure: Dictionary with {len(binary_data)} ML models\")\n",
        "    print(f\"  • Models: {list(binary_data.keys())}\")\n",
        "    print(f\"  • Each model contains: {list(next(iter(binary_data.values())).keys())}\")\n",
        "\n",
        "if hamza_file in results and results[hamza_file] is not None:\n",
        "    hamza_data = results[hamza_file]\n",
        "    print(f\"\\nLarge Hamza File:\")\n",
        "    print(f\"  • Structure: Dictionary with {len(hamza_data)} top-level key(s)\")\n",
        "    if 'classification_baseline' in hamza_data:\n",
        "        baseline_data = hamza_data['classification_baseline']\n",
        "        print(f\"  • Contains: {len(baseline_data)} subject records\")\n",
        "        print(f\"  • Subject ID pattern: {list(baseline_data.keys())[:3]}... (showing first 3)\")\n",
        "\n",
        "print(f\"\\n💡 KEY INSIGHTS:\")\n",
        "print(f\"  • Binary baseline file: Contains ML model results (3 models with metrics)\")\n",
        "print(f\"  • Large Hamza file: Contains individual subject data (271 subjects)\")\n",
        "print(f\"  • These appear to be different types of ML analysis results\")\n",
        "print(f\"  • Binary baseline: Model comparison results\")\n",
        "print(f\"  • Large Hamza: Subject-level analysis results\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🛠️  UTILITY FUNCTIONS FOR FURTHER EXPLORATION\n",
            "================================================================================\n",
            "🎯 EXAMPLE USAGE:\n",
            "------------------------------\n",
            "Available models: ['Logistic Regression', 'Random Forest', 'SVC']\n",
            "\n",
            "Metrics for Logistic Regression:\n",
            "{'accuracy': {'fold_scores': array([0.625     , 0.625     , 0.625     , 0.625     , 0.33333333]),\n",
            "              'mean': np.float64(0.5666666666666667),\n",
            "              'std': np.float64(0.11666666666666667)},\n",
            " 'f1': {'fold_scores': array([0.61904762, 0.56363636, 0.61904762, 0.61904762, 0.33333333]),\n",
            "        'mean': np.float64(0.5508225108225109),\n",
            "        'std': np.float64(0.11084198963013722)},\n",
            " 'roc_auc': {'fold_scores': array([0.625     , 0.625     , 0.625     , 0.625     , 0.33333333]),\n",
            "             'mean': np.float64(0.5666666666666667),\n",
            "             'std': np.float64(0.11666666666666665)}}\n",
            "\n",
            "Total subjects available: 271\n",
            "Sample subject IDs: ['MRC41', 'MLF61', 'MLC15', 'MRP32', 'MRT41']\n",
            "\n",
            "Data for MRC41:\n",
            "Keys: ['Logistic Regression', 'Random Forest', 'SVC']\n",
            "\n",
            "✅ Structure analysis complete!\n",
            "💡 You can now use the utility functions above to explore specific models or subjects.\n"
          ]
        }
      ],
      "source": [
        "# Utility functions for further exploration\n",
        "print(\"🛠️  UTILITY FUNCTIONS FOR FURTHER EXPLORATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def get_model_metrics(model_name, file_key='lsd_closed_hamza_binary_baseline_rs42.pkl'):\n",
        "    \"\"\"Extract metrics for a specific model from binary baseline file\"\"\"\n",
        "    if file_key in results and results[file_key] is not None:\n",
        "        data = results[file_key]\n",
        "        if model_name in data and 'metric_scores' in data[model_name]:\n",
        "            return data[model_name]['metric_scores']\n",
        "    return None\n",
        "\n",
        "def get_subject_data(subject_id, file_key='lsd_closed_Hamza.pkl'):\n",
        "    \"\"\"Extract data for a specific subject from large Hamza file\"\"\"\n",
        "    if file_key in results and results[file_key] is not None:\n",
        "        data = results[file_key]\n",
        "        if 'classification_baseline' in data:\n",
        "            baseline_data = data['classification_baseline']\n",
        "            if subject_id in baseline_data:\n",
        "                return baseline_data[subject_id]\n",
        "    return None\n",
        "\n",
        "def list_available_subjects(file_key='lsd_closed_Hamza.pkl'):\n",
        "    \"\"\"List all available subject IDs\"\"\"\n",
        "    if file_key in results and results[file_key] is not None:\n",
        "        data = results[file_key]\n",
        "        if 'classification_baseline' in data:\n",
        "            return list(data['classification_baseline'].keys())\n",
        "    return []\n",
        "\n",
        "def get_feature_importance(model_name, file_key='lsd_closed_hamza_binary_baseline_rs42.pkl'):\n",
        "    \"\"\"Get feature importance for a specific model\"\"\"\n",
        "    if file_key in results and results[file_key] is not None:\n",
        "        data = results[file_key]\n",
        "        if model_name in data and 'feature_importances' in data[model_name]:\n",
        "            return data[model_name]['feature_importances']\n",
        "    return None\n",
        "\n",
        "# Example usage:\n",
        "print(\"🎯 EXAMPLE USAGE:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Show available models\n",
        "if 'lsd_closed_hamza_binary_baseline_rs42.pkl' in results:\n",
        "    models = list(results['lsd_closed_hamza_binary_baseline_rs42.pkl'].keys())\n",
        "    print(f\"Available models: {models}\")\n",
        "    \n",
        "    # Get metrics for first model\n",
        "    if models:\n",
        "        first_model_metrics = get_model_metrics(models[0])\n",
        "        print(f\"\\nMetrics for {models[0]}:\")\n",
        "        if first_model_metrics:\n",
        "            pprint(first_model_metrics)\n",
        "\n",
        "# Show sample subjects\n",
        "subjects = list_available_subjects()\n",
        "if subjects:\n",
        "    print(f\"\\nTotal subjects available: {len(subjects)}\")\n",
        "    print(f\"Sample subject IDs: {subjects[:5]}\")\n",
        "    \n",
        "    # Get data for first subject\n",
        "    first_subject_data = get_subject_data(subjects[0])\n",
        "    print(f\"\\nData for {subjects[0]}:\")\n",
        "    if first_subject_data:\n",
        "        if isinstance(first_subject_data, dict):\n",
        "            print(f\"Keys: {list(first_subject_data.keys())}\")\n",
        "        else:\n",
        "            print(f\"Type: {type(first_subject_data)}\")\n",
        "\n",
        "print(f\"\\n✅ Structure analysis complete!\")\n",
        "print(f\"💡 You can now use the utility functions above to explore specific models or subjects.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deep analysis of the brain spatial regions and features structure\n",
        "print(\"🧠 BRAIN SPATIAL REGIONS AND FEATURES ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "hamza_file = 'lsd_closed_Hamza.pkl'\n",
        "if hamza_file in results and results[hamza_file] is not None:\n",
        "    data = results[hamza_file]\n",
        "    \n",
        "    if 'classification_baseline' in data:\n",
        "        baseline_data = data['classification_baseline']\n",
        "        \n",
        "        # Get first brain region data to understand structure\n",
        "        first_region_id = list(baseline_data.keys())[0]\n",
        "        first_region_data = baseline_data[first_region_id]\n",
        "        \n",
        "        print(f\"🏷️ Analyzing brain region: {first_region_id}\")\n",
        "        print(f\"📊 Total brain regions: {len(baseline_data)}\")\n",
        "        \n",
        "        if isinstance(first_region_data, dict):\n",
        "            print(f\"🤖 Models per region: {list(first_region_data.keys())}\")\n",
        "            \n",
        "            # Check first model to understand feature structure\n",
        "            first_model = list(first_region_data.keys())[0]\n",
        "            model_data = first_region_data[first_model]\n",
        "            \n",
        "            print(f\"\\n🔍 Examining model '{first_model}' for region '{first_region_id}':\")\n",
        "            print(f\"   📋 Model data keys: {list(model_data.keys())}\")\n",
        "            \n",
        "            # Look at feature importances to understand the 12 features\n",
        "            if 'feature_importances' in model_data:\n",
        "                features = model_data['feature_importances']\n",
        "                print(f\"\\n🎯 FEATURE ANALYSIS:\")\n",
        "                print(f\"   📏 Number of features: {len(features)}\")\n",
        "                print(f\"   🏷️ Feature names: {list(features.keys())}\")\n",
        "                \n",
        "                # Show actual feature importance values\n",
        "                print(f\"\\n   📊 Feature importance values for {first_region_id}:\")\n",
        "                for i, (feature_name, importance) in enumerate(features.items()):\n",
        "                    print(f\"      {i+1:2d}. {feature_name}: {importance:.6f}\")\n",
        "            \n",
        "            # Look at metrics structure\n",
        "            if 'metric_scores' in model_data:\n",
        "                metrics = model_data['metric_scores']\n",
        "                print(f\"\\n📈 METRICS STRUCTURE:\")\n",
        "                for metric_name, metric_data in metrics.items():\n",
        "                    if isinstance(metric_data, dict) and 'mean' in metric_data:\n",
        "                        print(f\"   {metric_name}: {metric_data['mean']:.4f} ± {metric_data.get('std', 0):.4f}\")\n",
        "        \n",
        "        # Sample a few more regions to check consistency\n",
        "        print(f\"\\n🔄 CONSISTENCY CHECK across regions:\")\n",
        "        sample_regions = list(baseline_data.keys())[:5]\n",
        "        \n",
        "        for region_id in sample_regions:\n",
        "            region_data = baseline_data[region_id]\n",
        "            if isinstance(region_data, dict):\n",
        "                models = list(region_data.keys())\n",
        "                first_model_data = region_data[models[0]]\n",
        "                if 'feature_importances' in first_model_data:\n",
        "                    n_features = len(first_model_data['feature_importances'])\n",
        "                    print(f\"   {region_id}: {n_features} features, models: {models}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CORRECT UNDERSTANDING OF DATA STRUCTURE\n",
        "print(\"🧠 CORRECTED DATA STRUCTURE ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "hamza_file = 'lsd_closed_Hamza.pkl'\n",
        "if hamza_file in results and results[hamza_file] is not None:\n",
        "    data = results[hamza_file]\n",
        "    \n",
        "    if 'classification_baseline' in data:\n",
        "        baseline_data = data['classification_baseline']\n",
        "        \n",
        "        # Get correct understanding\n",
        "        first_region = list(baseline_data.keys())[0]\n",
        "        region_data = baseline_data[first_region]\n",
        "        first_model = list(region_data.keys())[0]\n",
        "        model_data = region_data[first_model]\n",
        "        \n",
        "        # Extract key information\n",
        "        n_regions = len(baseline_data)\n",
        "        n_models = len(region_data)\n",
        "        n_features = len(model_data['feature_importances']) if 'feature_importances' in model_data else 0\n",
        "        \n",
        "        # Get number of subjects from predictions\n",
        "        n_subjects = 0\n",
        "        if 'predictions' in model_data and 'y_true' in model_data['predictions']:\n",
        "            n_subjects = len(model_data['predictions']['y_true'])\n",
        "        \n",
        "        # Get number of CV folds\n",
        "        n_folds = 0\n",
        "        if 'metric_scores' in model_data:\n",
        "            first_metric = list(model_data['metric_scores'].values())[0]\n",
        "            if isinstance(first_metric, dict) and 'fold_scores' in first_metric:\n",
        "                n_folds = len(first_metric['fold_scores'])\n",
        "        \n",
        "        print(f\"📊 DATASET DIMENSIONS:\")\n",
        "        print(f\"   🧠 Brain regions/channels: {n_regions}\")\n",
        "        print(f\"   🎯 Features per region: {n_features}\")\n",
        "        print(f\"   👥 Subjects in dataset: {n_subjects}\")\n",
        "        print(f\"   🤖 ML models per region: {n_models}\")\n",
        "        print(f\"   🔄 Cross-validation folds: {n_folds}\")\n",
        "        \n",
        "        print(f\"\\n🏷️ SAMPLE IDENTIFIERS:\")\n",
        "        print(f\"   Brain regions: {list(baseline_data.keys())[:10]}...\")\n",
        "        print(f\"   ML models: {list(region_data.keys())}\")\n",
        "        print(f\"   Features: {list(model_data['feature_importances'].keys())}\")\n",
        "        \n",
        "        print(f\"\\n📈 SAMPLE PERFORMANCE (region: {first_region}, model: {first_model}):\")\n",
        "        if 'metric_scores' in model_data:\n",
        "            for metric, metric_data in model_data['metric_scores'].items():\n",
        "                if isinstance(metric_data, dict) and 'mean' in metric_data:\n",
        "                    mean_score = metric_data['mean']\n",
        "                    std_score = metric_data.get('std', 0)\n",
        "                    print(f\"   {metric}: {mean_score:.4f} ± {std_score:.4f}\")\n",
        "        \n",
        "        print(f\"\\n🎯 FEATURE IMPORTANCE SAMPLE (region: {first_region}, model: {first_model}):\")\n",
        "        if 'feature_importances' in model_data:\n",
        "            feature_imp = model_data['feature_importances']\n",
        "            for i, (feat_name, importance) in enumerate(list(feature_imp.items())[:5]):\n",
        "                print(f\"   {feat_name}: {importance:.6f}\")\n",
        "            if len(feature_imp) > 5:\n",
        "                print(f\"   ... and {len(feature_imp) - 5} more features\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare with config file to understand feature names and spatial units\n",
        "print(\"📋 COMPARISON WITH CONFIG FILE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Features from config file\n",
        "config_features = [\n",
        "    \"feature-lzivComplexityMeanEpochs\",\n",
        "    \"feature-spectralEntropyMeanEpochs\", \n",
        "    \"feature-svdEntropyMeanEpochs\",\n",
        "    \"feature-hjorthComplexityMeanEpochs\",\n",
        "    \"feature-hjorthMobilityMeanEpochs\",\n",
        "    \"feature-higuchiFdMeanEpochs\",\n",
        "    \"feature-petrosianFdMeanEpochs\"\n",
        "]\n",
        "\n",
        "# Spatial units from config file  \n",
        "config_spatial_units = [\n",
        "    'MLC11', 'MLC12', 'MLC21', 'MLC22', 'MLC31', 'MLC32', 'MLF24', 'MLF31', 'MLF42', 'MLF51', 'MLF62', \n",
        "    'MLP21', 'MLP31', 'MLP42', 'MLP51', 'MLT11', 'MLT21', 'MLT31', 'MLT41', 'MLT51', 'MLO11', 'MLO21', \n",
        "    'MLO31', 'MLO41', 'MRC11', 'MRC21', 'MRC31', 'MRC41', 'MRF21', 'MRF31', 'MRF41', 'MRF51', 'MRP21', \n",
        "    'MRP31', 'MRP41', 'MRT21', 'MRT31', 'MRT41', 'MZC01', 'MZF01', 'MZO01', 'MZP01'\n",
        "]\n",
        "\n",
        "print(f\"🎯 Config file features ({len(config_features)}):\")\n",
        "for i, feature in enumerate(config_features, 1):\n",
        "    print(f\"   {i}. {feature}\")\n",
        "\n",
        "print(f\"\\n🧠 Config file spatial units ({len(config_spatial_units)}):\")\n",
        "print(f\"   Sample: {config_spatial_units[:10]}...\")\n",
        "\n",
        "# Compare with pickle data\n",
        "hamza_file = 'lsd_closed_Hamza.pkl'\n",
        "if hamza_file in results and results[hamza_file] is not None:\n",
        "    data = results[hamza_file]\n",
        "    \n",
        "    if 'classification_baseline' in data:\n",
        "        baseline_data = data['classification_baseline']\n",
        "        \n",
        "        # Get actual regions from pickle\n",
        "        pickle_regions = list(baseline_data.keys())\n",
        "        \n",
        "        print(f\"\\n📊 PICKLE vs CONFIG COMPARISON:\")\n",
        "        print(f\"   Config spatial units: {len(config_spatial_units)}\")\n",
        "        print(f\"   Pickle brain regions: {len(pickle_regions)}\")\n",
        "        \n",
        "        # Check overlap\n",
        "        config_set = set(config_spatial_units)\n",
        "        pickle_set = set(pickle_regions)\n",
        "        \n",
        "        overlap = config_set.intersection(pickle_set)\n",
        "        config_only = config_set - pickle_set\n",
        "        pickle_only = pickle_set - config_set\n",
        "        \n",
        "        print(f\"\\n🔍 OVERLAP ANALYSIS:\")\n",
        "        print(f\"   Regions in both: {len(overlap)}\")\n",
        "        print(f\"   Only in config: {len(config_only)}\")\n",
        "        print(f\"   Only in pickle: {len(pickle_only)}\")\n",
        "        \n",
        "        if len(overlap) > 0:\n",
        "            print(f\"   Sample overlap: {list(overlap)[:10]}\")\n",
        "        \n",
        "        if len(config_only) > 0:\n",
        "            print(f\"   Sample config-only: {list(config_only)[:10]}\")\n",
        "            \n",
        "        if len(pickle_only) > 0:\n",
        "            print(f\"   Sample pickle-only: {list(pickle_only)[:10]}\")\n",
        "        \n",
        "        # Check if we can find patterns in the 12 features vs 7 config features\n",
        "        first_region_data = baseline_data[pickle_regions[0]]\n",
        "        if isinstance(first_region_data, dict):\n",
        "            first_model_data = first_region_data[list(first_region_data.keys())[0]]\n",
        "            if 'feature_importances' in first_model_data:\n",
        "                pickle_features = list(first_model_data['feature_importances'].keys())\n",
        "                \n",
        "                print(f\"\\n🎯 FEATURE COMPARISON:\")\n",
        "                print(f\"   Config features: {len(config_features)}\")\n",
        "                print(f\"   Pickle features: {len(pickle_features)}\")\n",
        "                \n",
        "                print(f\"\\n   Pickle feature names:\")\n",
        "                for i, feat in enumerate(pickle_features, 1):\n",
        "                    print(f\"      {i:2d}. {feat}\")\n",
        "                \n",
        "                # Try to map pickle features to config features\n",
        "                print(f\"\\n🔗 FEATURE MAPPING ANALYSIS:\")\n",
        "                for pickle_feat in pickle_features:\n",
        "                    # Look for partial matches\n",
        "                    matches = [config_feat for config_feat in config_features \n",
        "                             if any(part in config_feat.lower() for part in pickle_feat.lower().split('_'))]\n",
        "                    if matches:\n",
        "                        print(f\"   {pickle_feat} → potential match: {matches[0]}\")\n",
        "                    else:\n",
        "                        print(f\"   {pickle_feat} → no clear match\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "coco",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
